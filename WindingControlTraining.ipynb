{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os, os.path\n",
    "import keras\n",
    "import time\n",
    "import scipy.misc\n",
    "import scipy.ndimage\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.initializers import RandomUniform, RandomNormal\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolution of images\n",
    "\n",
    "h = 75\n",
    "w = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates list of positiv files\n",
    "positiv_list = glob.glob('/fhgfs/groups/e5/lhcb/detector/scifi/windingcontrol/Images_Sep17/pos/IMG_*.png')\n",
    "#Finds the number of positiv files\n",
    "positiv_len = len(positiv_list)\n",
    "print(\"Size of positiv Sample: {}\".format(positiv_len))\n",
    "\n",
    "#Same but for negativ files\n",
    "negativ_list = glob.glob('/fhgfs/groups/e5/lhcb/detector/scifi/windingcontrol/Images_Sep17/neg/IMG_*.png')\n",
    "negativ_len = len(negativ_list)\n",
    "print(\"Size of negativ Sample: {}\".format(negativ_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_posind = []\n",
    "X_negind = []\n",
    "X_posinu = []\n",
    "X_neginu = []\n",
    "X_posinl = []\n",
    "X_neginl = []\n",
    "X_posinr = []\n",
    "X_neginr = []\n",
    "\n",
    "X_pos = []\n",
    "X_neg = []\n",
    "\n",
    "for fname in tqdm(positiv_list):\n",
    "    img = scipy.misc.imresize(np.array(Image.open(fname)),(h,w))\n",
    "    \n",
    "    #X_posind.append(scipy.ndimage.interpolation.shift(img, (20,0), output=None, order=1, mode='nearest', cval=0.0, prefilter=True))\n",
    "    #X_posinu.append(scipy.ndimage.interpolation.shift(img, (-20,0), output=None, order=1, mode='nearest', cval=0.0, prefilter=True))\n",
    "    \n",
    "    #X_posinr.append(scipy.ndimage.interpolation.shift(img, (0,50), output=None, order=1, mode='reflect', cval=0.0, prefilter=True))\n",
    "    #X_posinl.append(scipy.ndimage.interpolation.shift(img, (0,-50), output=None, order=1, mode='reflect', cval=0.0, prefilter=True))\n",
    "    \n",
    "    X_pos.append(img) \n",
    "    \n",
    "# Random picking of neg images with the given ratio to the pos images\n",
    "ratio_pos_neg = 1\n",
    "    \n",
    "for fname in tqdm(np.random.choice(negativ_list, replace=False, size=int(len(X_pos) / ratio_pos_neg))):\n",
    "    img = scipy.misc.imresize(np.array(Image.open(fname)),(h,w))\n",
    "    \n",
    "    #X_negind.append(scipy.ndimage.interpolation.shift(img, (20,0), output=None, order=1, mode='nearest', cval=0.0, prefilter=True))\n",
    "    #X_neginu.append(scipy.ndimage.interpolation.shift(img, (-20,0), output=None, order=1, mode='nearest', cval=0.0, prefilter=True))\n",
    "    \n",
    "    #X_neginr.append(scipy.ndimage.interpolation.shift(img, (0,50), output=None, order=1, mode='reflect', cval=0.0, prefilter=True))\n",
    "    #X_neginl.append(scipy.ndimage.interpolation.shift(img, (0,-50), output=None, order=1, mode='reflect', cval=0.0, prefilter=True))\n",
    "    \n",
    "    X_neg.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_posind = np.array(X_posind)\n",
    "X_negind = np.array(X_negind)\n",
    "X_posinu = np.array(X_posinu)\n",
    "X_neginu = np.array(X_neginu)\n",
    "X_posinl = np.array(X_posinl)\n",
    "X_neginl = np.array(X_neginl)\n",
    "X_posinr = np.array(X_posinr)\n",
    "X_neginr = np.array(X_neginr)\n",
    "X_pos = np.array(X_pos)\n",
    "X_neg = np.array(X_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.concatenate((X_pos, X_neg), axis=0)\n",
    "Y_all = np.concatenate( ( np.ones(len(X_pos)), np.zeros(len(X_neg)) ) , axis=0)\n",
    "#X_all_trans = np.concatenate((X_pos, X_posind, X_posinu, X_posinl, X_posinr, X_neg, X_negind, X_neginu, X_neginl, X_neginr), axis=0)\n",
    "#Y_all_trans = np_utils.to_categorical(np.concatenate((np.ones((5*positiv_len, 1)), np.zeros((5*negativ_len,1))), axis=0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the order of the input - required to avoid batches selecting only positive/negative images\n",
    "randomize = np.arange(len(X_all))\n",
    "np.random.shuffle(randomize)\n",
    "X_all = X_all[randomize]\n",
    "Y_all = Y_all[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check labeling of Data\n",
    "if False:\n",
    "    for i, img in enumerate(X_all[:200]):\n",
    "        plt.imshow(np.squeeze(img), cmap='gray')\n",
    "\n",
    "        name = \"Good img\" if Y_all[i] == 1 else \"Bad img\"\n",
    "        plt.title('{}.'.format(name))\n",
    "        plt.savefig('../Plots/TestImg/{}.png'.format(i))\n",
    "        if i%10 == 0:\n",
    "            print(\"10 written\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold 5% back as training data\n",
    "train_split = int(0.05 * len(X_all))\n",
    "\n",
    "# Separate in Training and Testing Sample\n",
    "X_train = X_all[train_split:]\n",
    "Y_train = Y_all[train_split:]\n",
    "\n",
    "X_test = X_all[:train_split]\n",
    "Y_test = Y_all[:train_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check labeling of Data\n",
    "if False:\n",
    "    for i, img in enumerate(X_test[:100]):\n",
    "        plt.imshow(np.squeeze(img), cmap='gray')\n",
    "\n",
    "        name = \"Good img\" if Y_test[i] == 1 else \"Bad img\"\n",
    "        plt.title('{}.'.format(name))\n",
    "        plt.savefig('../Plots/TestImg/{}.png'.format(i))\n",
    "        if i%10 == 0:\n",
    "            print(\"10 written\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], h, w, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], h, w, 1)\n",
    "\n",
    "#Shape check (NumberofImages, Height, Width, Depth)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with lower resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = 30\n",
    "y_new = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_30_40 = []\n",
    "for img in X_all:\n",
    "    X_all_30_40.append(scipy.misc.imresize(np.array(img),(x_new,y_new)))\n",
    "    \n",
    "X_all_30_40 = np.array(X_all_30_40)\n",
    "Y_all_30_40 = Y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the order of the input - required to avoid batches selecting only positive/negative images\n",
    "randomize = np.arange(len(X_all))\n",
    "np.random.shuffle(randomize)\n",
    "X_all_30_40 = X_all_30_40[randomize]\n",
    "Y_all_30_40 = Y_all_30_40[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold 5% back as training data\n",
    "train_split = int(0.05 * len(X_all_30_40))\n",
    "\n",
    "# Separate in Training and Testing Sample\n",
    "X_train_30_40 = X_all_30_40[train_split:]\n",
    "Y_train_30_40 = Y_all_30_40[train_split:]\n",
    "\n",
    "X_test_30_40 = X_all_30_40[:train_split]\n",
    "Y_test_30_40 = Y_all_30_40[:train_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_30_40 = X_train_30_40.reshape(X_train_30_40.shape[0], x_new, y_new, 1)\n",
    "X_test_30_40 = X_test_30_40.reshape(X_test_30_40.shape[0], x_new, y_new, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data need to be normalised\n",
    "* Mean and StdDev for each pixel over whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(X_train, axis=0)\n",
    "stds = np.std(X_train, axis=0)\n",
    "\n",
    "#means_30_40 = np.mean(X_train_30_40, axis=0)\n",
    "#stds_30_40 = np.std(X_train_30_40, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(means.shape)\n",
    "print(stds.shape)\n",
    "#print(means_30_40.shape)\n",
    "#print(stds_30_40.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_meanstd = '../TrainedModels/' + str(datetime.now().strftime('%Y-%m-%d')) + '/MeansStdDev/'\n",
    "\n",
    "if not os.path.exists(path_meanstd):\n",
    "    os.makedirs(path_meanstd)\n",
    "    print('Created path: {}'.format(path_meanstd))\n",
    "                                            \n",
    "#np.savetxt('../Data/Means_30_40.txt', means_30_40)\n",
    "#np.savetxt('../Data/StdDev_30_40.txt', stds_30_40)\n",
    "np.savetxt(path_meanstd +'Means_' +  str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) +  '.txt', means)\n",
    "np.savetxt(path_meanstd +'StdDev_' +  str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) +  '.txt', stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(means), cmap='gray')\n",
    "plt.savefig(path_meanstd + 'MeanImg' +  str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(stds), cmap='gray')\n",
    "plt.savefig(path_meanstd + 'StdImg' +  str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = np.array([(img-means)/stds for img in X_train])\n",
    "X_test_norm = np.array([(img-means)/stds for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_30_40_norm = np.array([(img-means_30_40)/stds_30_40 for img in X_train_30_40])\n",
    "#X_test_30_40_norm = np.array([(img-means_30_40)/stds_30_40 for img in X_test_30_40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let the training begin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Class to get loss and accuracy during training of NN\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.accuracy = []\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accuracy.append(logs.get('acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape= (h,w,1)\n",
    "#input_shape_30_40= (x_new,y_new,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* initializer need to have mean = 0 and std 1/input_shape\n",
    "* for successive layers output shape of previous layer will declare this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = '../TrainedModels/' + str(datetime.now().strftime('%Y-%m-%d')) + '/'\n",
    "\n",
    "if not os.path.exists(path_model):\n",
    "    os.makedirs(path_model)\n",
    "    print('Created path: {}'.format(path_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# First Convolutional layer initialised with random input weights\n",
    "model.add(Conv2D(16, (7,7), kernel_initializer=RandomNormal(mean=0, stddev=1/(h*w)), padding='valid', input_shape=input_shape, activation='selu'))\n",
    "# Reduce size a bit\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "mult_shape1 = np.prod(model.layers[1].output_shape[1:])\n",
    "\n",
    "# Second Convolutional layer\n",
    "model.add(Conv2D(16, (5,5), kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape1), padding='valid', activation='selu'))\n",
    "# Reduce size a bit\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "mult_shape2 = np.prod(model.layers[3].output_shape[1:])\n",
    "\n",
    "# Third Convolutional layer\n",
    "model.add(Conv2D(16, (3,3), kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape2), padding='valid', activation='selu'))\n",
    "# Reduce size a bit\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Converting the 2D images to 1D vectors\n",
    "model.add(Flatten())  \n",
    "mult_shape3 = np.prod(model.layers[6].output_shape[1:])\n",
    "\n",
    "# First Fully connected layer\n",
    "model.add(Dense(200, activation='selu', kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape3)))\n",
    "model.add(Dropout(0.2))\n",
    "mult_shape4 = np.prod(model.layers[8].output_shape[1:])\n",
    "\n",
    "#model.add(Dense(200, activation='selu', kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape4)))\n",
    "#model.add(Dropout(0.2))\n",
    "#mult_shape5 = np.prod(model.layers[10].output_shape[1:])\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='167_165_163_200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "\n",
    "path_data = '../Data/{}/{}/'.format(str(datetime.now().strftime('%Y-%m-%d')), name )\n",
    "\n",
    "if not os.path.exists(path_data):\n",
    "    os.makedirs(path_data)\n",
    "    print('Created path: {}'.format(path_data))\n",
    "\n",
    "# Open the file\n",
    "with open(path_data + 'ModelSummary.txt','w') as fh:\n",
    "    # Pass the file handle in as a lambda function to make it callable\n",
    "    model.summary(print_fn=lambda x: fh.write(x + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining optimiser and compiling the model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to continue a training\n",
    "if False:\n",
    "    model = load_model('../TrainedModels/2017-09-09/169_167_200_200_selu_100epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train_norm, Y_train,  batch_size=76, epochs=100, verbose=1, validation_split = 0.05, callbacks=[history])\n",
    "\n",
    "#Evaluating trained model on test images\n",
    "score = model.evaluate(X_test_norm, Y_test, verbose=0)\n",
    "print('Model has accuracy:', score[1]*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save trained NN - USE DIFFERENT NAME FOR NEW NETWORK\n",
    "model.save(path_model + name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(path_model + name + '_TrainingData.txt', np.transpose([history.accuracy, history.losses]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and Losss during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.array(history.accuracy)\n",
    "losses = np.array(history.losses)\n",
    "\n",
    "fig, ax = plt.subplots(2, sharex=True)\n",
    "\n",
    "every_item = 100\n",
    "\n",
    "ax[0].plot(accuracy[::every_item], color = 'b', marker='', ls='-')\n",
    "ax[1].plot(losses[::every_item], color = 'm', marker='', ls='-')\n",
    "\n",
    "ax[1].set_xlabel('batch number')\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[1].set_ylabel('loss')\n",
    "\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "ax[0].set_title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_data + '/LossAccLog::{}.png'.format(every_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probs per image\n",
    "probs = []\n",
    "\n",
    "i=0 \n",
    "for img in X_test_norm:\n",
    "    #plt.imshow(np.squeeze(img), cmap='gray')\n",
    "    \n",
    "    img = np.reshape(img, [1,h,w,1])\n",
    "    p = model.predict_proba(img, verbose=0)\n",
    "    probs.append(np.squeeze(p))\n",
    "    \n",
    "    #name = \"Good img\" if Y_test[i, 1] == 1 else \"Bad img\"\n",
    "    #plt.title('{}. Score: [{:.4f}, {:.4f}]'.format(name, p[0,0], p[0,1]))\n",
    "    #plt.savefig('../Plots/TestImg/{}.png'.format(i))\n",
    "    i+=1\n",
    "\n",
    "probs = np.array(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(path_data + 'ScoresOnTestData.txt', np.transpose([Y_test, probs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pos = Y_test\n",
    "score_pos = probs[label_pos == 1]\n",
    "score_neg = probs[label_pos == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "binsize = 0.05\n",
    "bins = np.arange(0, 1 + binsize, binsize)\n",
    "\n",
    "ax.hist(score_neg, bins=bins, histtype='stepfilled', linewidth=1, edgecolor='m', color='#ff99ff', label='neg img')\n",
    "ax.hist(score_pos, bins=bins, histtype='stepfilled', linewidth=1, edgecolor='b', color='#6666ff', label='pos img')\n",
    "\n",
    "ax.hist(score_neg, bins=bins, histtype='step', linewidth=1, linestyle='-', edgecolor='m')\n",
    "ax.hist(score_pos, bins=bins, histtype='step', linewidth=1, linestyle='-',edgecolor='b')\n",
    "\n",
    "ax.set_xlabel(\"Score for pos img\")\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.legend(loc='best')\n",
    "\n",
    "plt.title('Test Data')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_data + 'ScoreDistributionOnTestData_{}.png'.format(binsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive images below 0.5\n",
    "img_pos = X_test_norm[label_pos == 1]\n",
    "img_pos_false = img_pos[score_pos < 0.5]\n",
    "score_pos_false = score_pos[score_pos < 0.5]\n",
    "print(img_pos_false.shape)\n",
    "\n",
    "# negative images over 0.5\n",
    "img_neg = X_test_norm[label_pos == 0]\n",
    "img_neg_false = img_neg[score_neg > 0.5]\n",
    "score_neg_false = score_neg[score_neg > 0.5]\n",
    "print(img_neg_false.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wrongly classified pics:\n",
    "\n",
    "for i, (pic,p) in enumerate(zip(img_pos_false[:], score_pos_false[:])):\n",
    "    plt.imshow(np.squeeze(pic), cmap='gray')\n",
    "    \n",
    "    plt.title('Score: {:}'.format(p))\n",
    "    plt.savefig(path_data + 'wrongImg/pos_{}.png'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## wrongly classified pics:\n",
    "\n",
    "for i, (pic,p) in enumerate(zip(img_neg_false[:], score_neg_false[:])):\n",
    "    plt.imshow(np.squeeze(pic), cmap='gray')\n",
    "    \n",
    "    plt.title('Score: {:}'.format(p))\n",
    "    plt.savefig(path_data + 'wrongImg/neg_{}.png'.format(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
