{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K40m (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os, os.path\n",
    "import keras\n",
    "import time\n",
    "import scipy.misc\n",
    "import scipy.ndimage\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.initializers import RandomUniform, RandomNormal\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resolution of images\n",
    "\n",
    "h = 75\n",
    "w = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of positiv Sample: 8590\n",
      "Size of negativ Sample: 13846\n"
     ]
    }
   ],
   "source": [
    "#Creates list of positiv files\n",
    "positiv_list = glob.glob('/fhgfs/groups/e5/lhcb/detector/scifi/windingcontrol/Images_Sep17/pos/IMG_*.png')\n",
    "#Finds the number of positiv files\n",
    "positiv_len = len(positiv_list)\n",
    "print(\"Size of positiv Sample: {}\".format(positiv_len))\n",
    "\n",
    "#Same but for negativ files\n",
    "negativ_list = glob.glob('/fhgfs/groups/e5/lhcb/detector/scifi/windingcontrol/Images_Sep17/neg/IMG_*.png')\n",
    "negativ_len = len(negativ_list)\n",
    "print(\"Size of negativ Sample: {}\".format(negativ_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8590/8590 [00:37<00:00, 226.72it/s]\n",
      "100%|██████████| 13846/13846 [01:22<00:00, 168.27it/s]\n"
     ]
    }
   ],
   "source": [
    "X_posind = []\n",
    "X_negind = []\n",
    "X_posinu = []\n",
    "X_neginu = []\n",
    "X_posinl = []\n",
    "X_neginl = []\n",
    "X_posinr = []\n",
    "X_neginr = []\n",
    "\n",
    "X_pos = []\n",
    "X_neg = []\n",
    "\n",
    "for fname in tqdm(positiv_list):\n",
    "    img = scipy.misc.imresize(np.array(Image.open(fname)),(h,w))\n",
    "    \n",
    "    #X_posind.append(scipy.ndimage.interpolation.shift(img, (20,0), output=None, order=1, mode='nearest', cval=0.0, prefilter=True))\n",
    "    #X_posinu.append(scipy.ndimage.interpolation.shift(img, (-20,0), output=None, order=1, mode='nearest', cval=0.0, prefilter=True))\n",
    "    \n",
    "    #X_posinr.append(scipy.ndimage.interpolation.shift(img, (0,50), output=None, order=1, mode='reflect', cval=0.0, prefilter=True))\n",
    "    #X_posinl.append(scipy.ndimage.interpolation.shift(img, (0,-50), output=None, order=1, mode='reflect', cval=0.0, prefilter=True))\n",
    "    \n",
    "    X_pos.append(img) \n",
    "    \n",
    "# Random picking of neg images with the given ratio to the pos images\n",
    "ratio_pos_neg = 1\n",
    "\n",
    "for fname in tqdm(negativ_list):\n",
    "#for fname in tqdm(np.random.choice(negativ_list, replace=False, size=int(len(X_pos) / ratio_pos_neg))):\n",
    "    img = scipy.misc.imresize(np.array(Image.open(fname)),(h,w))\n",
    "    \n",
    "    #X_negind.append(scipy.ndimage.interpolation.shift(img, (20,0), output=None, order=1, mode='nearest', cval=0.0, prefilter=True))\n",
    "    #X_neginu.append(scipy.ndimage.interpolation.shift(img, (-20,0), output=None, order=1, mode='nearest', cval=0.0, prefilter=True))\n",
    "    \n",
    "    #X_neginr.append(scipy.ndimage.interpolation.shift(img, (0,50), output=None, order=1, mode='reflect', cval=0.0, prefilter=True))\n",
    "    #X_neginl.append(scipy.ndimage.interpolation.shift(img, (0,-50), output=None, order=1, mode='reflect', cval=0.0, prefilter=True))\n",
    "    \n",
    "    X_neg.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_posind = np.array(X_posind)\n",
    "X_negind = np.array(X_negind)\n",
    "X_posinu = np.array(X_posinu)\n",
    "X_neginu = np.array(X_neginu)\n",
    "X_posinl = np.array(X_posinl)\n",
    "X_neginl = np.array(X_neginl)\n",
    "X_posinr = np.array(X_posinr)\n",
    "X_neginr = np.array(X_neginr)\n",
    "X_pos = np.array(X_pos)\n",
    "X_neg = np.array(X_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = np.concatenate((X_pos, X_neg), axis=0)\n",
    "Y_all = np.concatenate( ( np.ones(len(X_pos)), np.zeros(len(X_neg)) ) , axis=0)\n",
    "#X_all_trans = np.concatenate((X_pos, X_posind, X_posinu, X_posinl, X_posinr, X_neg, X_negind, X_neginu, X_neginl, X_neginr), axis=0)\n",
    "#Y_all_trans = np_utils.to_categorical(np.concatenate((np.ones((5*positiv_len, 1)), np.zeros((5*negativ_len,1))), axis=0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22436, 75, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22436,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling the order of the input - required to avoid batches selecting only positive/negative images\n",
    "randomize = np.arange(len(X_all))\n",
    "np.random.shuffle(randomize)\n",
    "X_all = X_all[randomize]\n",
    "Y_all = Y_all[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check labeling of Data\n",
    "if False:\n",
    "    for i, img in enumerate(X_all[:200]):\n",
    "        plt.imshow(np.squeeze(img), cmap='gray')\n",
    "\n",
    "        name = \"Good img\" if Y_all[i] == 1 else \"Bad img\"\n",
    "        plt.title('{}.'.format(name))\n",
    "        plt.savefig('../Plots/TestImg/{}.png'.format(i))\n",
    "        if i%10 == 0:\n",
    "            print(\"10 written\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hold 5% back as training data\n",
    "train_split = int(0.05 * len(X_all))\n",
    "\n",
    "# Separate in Training and Testing Sample\n",
    "X_train = X_all[train_split:]\n",
    "Y_train = Y_all[train_split:]\n",
    "\n",
    "X_test = X_all[:train_split]\n",
    "Y_test = Y_all[:train_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check labeling of Data\n",
    "if False:\n",
    "    for i, img in enumerate(X_test[:100]):\n",
    "        plt.imshow(np.squeeze(img), cmap='gray')\n",
    "\n",
    "        name = \"Good img\" if Y_test[i] == 1 else \"Bad img\"\n",
    "        plt.title('{}.'.format(name))\n",
    "        plt.savefig('../Plots/TestImg/{}.png'.format(i))\n",
    "        if i%10 == 0:\n",
    "            print(\"10 written\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21315, 75, 100, 1)\n",
      "(21315,)\n",
      "(1121, 75, 100, 1)\n",
      "(1121,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], h, w, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], h, w, 1)\n",
    "\n",
    "#Shape check (NumberofImages, Height, Width, Depth)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data need to be normalised\n",
    "* Mean and StdDev for each pixel over whole data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21315, 75, 100, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "means = np.mean(X_train, axis=0)\n",
    "stds = np.std(X_train, axis=0)\n",
    "\n",
    "#means_30_40 = np.mean(X_train_30_40, axis=0)\n",
    "#stds_30_40 = np.std(X_train_30_40, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 100, 1)\n",
      "(75, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(means.shape)\n",
    "print(stds.shape)\n",
    "#print(means_30_40.shape)\n",
    "#print(stds_30_40.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created path: ../TrainedModels/2017-09-16/MeansStdDev/\n"
     ]
    }
   ],
   "source": [
    "path_meanstd = '../TrainedModels/' + str(datetime.now().strftime('%Y-%m-%d')) + '/MeansStdDev/'\n",
    "\n",
    "if not os.path.exists(path_meanstd):\n",
    "    os.makedirs(path_meanstd)\n",
    "    print('Created path: {}'.format(path_meanstd))\n",
    "                                            \n",
    "#np.savetxt('../Data/Means_30_40.txt', means_30_40)\n",
    "#np.savetxt('../Data/StdDev_30_40.txt', stds_30_40)\n",
    "np.savetxt(path_meanstd +'Means_' +  str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) +  '.txt', means)\n",
    "np.savetxt(path_meanstd +'StdDev_' +  str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) +  '.txt', stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAD8CAYAAADkM2ZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYQY/D/08CIIQwjeiAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcf09627860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(means), cmap='gray')\n",
    "plt.savefig(path_meanstd + 'MeanImg' +  str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUcAAAD8CAYAAADkM2ZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAN2joQQYvD/blhamCJkumYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcf09459f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(stds), cmap='gray')\n",
    "plt.savefig(path_meanstd + 'StdImg' +  str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_norm = np.array([(img-means)/stds for img in X_train])\n",
    "X_test_norm = np.array([(img-means)/stds for img in X_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let the training begin..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Class to get loss and accuracy during training of NN\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.accuracy = []\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accuracy.append(logs.get('acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape= (h,w,1)\n",
    "#input_shape_30_40= (x_new,y_new,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* initializer need to have mean = 0 and std 1/input_shape\n",
    "* for successive layers output shape of previous layer will declare this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with 3 Conv Layer and 2 Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_3Conv_2Fully = ['167_165_163_200_200', '165_165_163_200_200', '165_163_163_200_200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_sizes_3Conv_2Fully = [(7,5,3), (5,5,3), (5,3,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 167_165_163_200_200\tKernelsize: (7, 5, 3)\n",
      "k_sizes: 7,5,3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 69, 94, 16)        800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 34, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 43, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 21, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 19, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 9, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               173000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 222,937\n",
      "Trainable params: 222,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Name: 165_165_163_200_200\tKernelsize: (5, 5, 3)\n",
      "k_sizes: 5,5,3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 71, 96, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 35, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 31, 44, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 22, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 13, 20, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 10, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               192200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 241,753\n",
      "Trainable params: 241,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Name: 165_163_163_200_200\tKernelsize: (5, 3, 3)\n",
      "k_sizes: 5,3,3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 71, 96, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 35, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 33, 46, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 21, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 10, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1120)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               224200    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 269,657\n",
      "Trainable params: 269,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for name, k_size in zip(names_3Conv_2Fully, kernel_sizes_3Conv_2Fully):    \n",
    "    print('Name: {}\\tKernelsize: {}'.format(name, k_size))\n",
    "    #print('k_sizes: {},{},{}'.format(k_size[0], k_size[1], k_size[2]))\n",
    "    \n",
    "    ## Path for Model saving!\n",
    "    path_model = '../TrainedModels/' + str(datetime.now().strftime('%Y-%m-%d')) + '/'\n",
    "\n",
    "    if not os.path.exists(path_model):\n",
    "        os.makedirs(path_model)\n",
    "        print('Created path: {}'.format(path_model))\n",
    "        \n",
    "    ##### MODEL #####\n",
    "    model = Sequential()\n",
    "\n",
    "    # First Convolutional layer initialised with random input weights\n",
    "    model.add(Conv2D(16, (k_size[0], k_size[0]), kernel_initializer=RandomNormal(mean=0, stddev=1/(h*w)), padding='valid', input_shape=input_shape, activation='selu'))\n",
    "    # Reduce size a bit\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    mult_shape1 = np.prod(model.layers[1].output_shape[1:])\n",
    "\n",
    "    # Second Convolutional layer\n",
    "    model.add(Conv2D(16, (k_size[1], k_size[1]), kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape1), padding='valid', activation='selu'))\n",
    "    # Reduce size a bit\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    mult_shape2 = np.prod(model.layers[3].output_shape[1:])\n",
    "\n",
    "    # Third Convolutional layer\n",
    "    model.add(Conv2D(16, (k_size[2], k_size[2]), kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape2), padding='valid', activation='selu'))\n",
    "    # Reduce size a bit\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    #Converting the 2D images to 1D vectors\n",
    "    model.add(Flatten())  \n",
    "    mult_shape3 = np.prod(model.layers[6].output_shape[1:])\n",
    "\n",
    "    # First Fully connected layer\n",
    "    model.add(Dense(200, activation='selu', kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    mult_shape4 = np.prod(model.layers[8].output_shape[1:])\n",
    "\n",
    "    # Second Fully connected layer\n",
    "    model.add(Dense(200, activation='selu', kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape4)))\n",
    "    model.add(Dropout(0.2))\n",
    "    mult_shape5 = np.prod(model.layers[10].output_shape[1:])\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape5)))\n",
    "    \n",
    "    #### END OF MODEL ####\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    ## Save the Model and create Data path!\n",
    "    path_data = '../Data/{}/{}/'.format(str(datetime.now().strftime('%Y-%m-%d')), name )\n",
    "\n",
    "    if not os.path.exists(path_data):\n",
    "        os.makedirs(path_data)\n",
    "        print('Created path: {}'.format(path_data))\n",
    "\n",
    "    # Open the file\n",
    "    with open(path_data + 'ModelSummary.txt','w') as fh:\n",
    "        # Pass the file handle in as a lambda function to make it callable\n",
    "        model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "        \n",
    "    \n",
    "    #Defining optimiser and compiling the model\n",
    "    model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "                  optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = LossHistory()\n",
    "    \n",
    "    ## Start the training!\n",
    "    model.fit(X_train_norm, Y_train,  batch_size=76, epochs=100, verbose=1, validation_split = 0.05, callbacks=[history])\n",
    "\n",
    "    #Evaluating trained model on test images\n",
    "    score = model.evaluate(X_test_norm, Y_test, verbose=0)\n",
    "    print('Model has accuracy:', score[1]*100,'%')\n",
    "    \n",
    "    # Save trained NN\n",
    "    model.save(path_model + name + '.h5')\n",
    "    np.savetxt(path_model + name + '_TrainingData.txt', np.transpose([history.accuracy, history.losses]))\n",
    "    \n",
    "    ### Performance on Testdata! ###\n",
    "    # Get probs per image\n",
    "    probs = []\n",
    "\n",
    "    i=0 \n",
    "    for img in X_test_norm:\n",
    "        #plt.imshow(np.squeeze(img), cmap='gray')\n",
    "\n",
    "        img = np.reshape(img, [1,h,w,1])\n",
    "        p = model.predict_proba(img, verbose=0)\n",
    "        probs.append(np.squeeze(p))\n",
    "\n",
    "        #name = \"Good img\" if Y_test[i, 1] == 1 else \"Bad img\"\n",
    "        #plt.title('{}. Score: [{:.4f}, {:.4f}]'.format(name, p[0,0], p[0,1]))\n",
    "        #plt.savefig('../Plots/TestImg/{}.png'.format(i))\n",
    "        i+=1\n",
    "\n",
    "    probs = np.array(probs)\n",
    "    \n",
    "    np.savetxt(path_data + 'ScoresOnTestData.txt', np.transpose([Y_test, probs]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with 3 Conv Layer and 1 Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_3Conv_1Fully = ['167_165_163_200', '165_165_163_200', '165_163_163_200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_sizes_3Conv_1Fully = [(7,5,3), (5,5,3), (5,3,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 167_165_163_200\tKernelsize: (7, 5, 3)\n",
      "k_sizes: 7,5,3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 69, 94, 16)        800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 34, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 30, 43, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 15, 21, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 13, 19, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 6, 9, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 864)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 200)               173000    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 182,737\n",
      "Trainable params: 182,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Name: 165_165_163_200\tKernelsize: (5, 5, 3)\n",
      "k_sizes: 5,5,3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 71, 96, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 35, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 31, 44, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 15, 22, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 13, 20, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 6, 10, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 200)               192200    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 201,553\n",
      "Trainable params: 201,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Name: 165_163_163_200\tKernelsize: (5, 3, 3)\n",
      "k_sizes: 5,3,3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 71, 96, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 35, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 33, 46, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 16, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 14, 21, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 7, 10, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1120)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 200)               224200    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 229,457\n",
      "Trainable params: 229,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for name, k_size in zip(names_3Conv_1Fully, kernel_sizes_3Conv_1Fully):\n",
    "    print('Name: {}\\tKernelsize: {}'.format(name, k_size))\n",
    "    #print('k_sizes: {},{},{}'.format(k_size[0], k_size[1], k_size[2]))\n",
    "    \n",
    "    ## Path for Model saving!\n",
    "    path_model = '../TrainedModels/' + str(datetime.now().strftime('%Y-%m-%d')) + '/'\n",
    "\n",
    "    if not os.path.exists(path_model):\n",
    "        os.makedirs(path_model)\n",
    "        print('Created path: {}'.format(path_model))\n",
    "    \n",
    "    #### MODEL ####\n",
    "    model = Sequential()\n",
    "\n",
    "    # First Convolutional layer initialised with random input weights\n",
    "    model.add(Conv2D(16, (k_size[0], k_size[0]), kernel_initializer=RandomNormal(mean=0, stddev=1/(h*w)), padding='valid', input_shape=input_shape, activation='selu'))\n",
    "    # Reduce size a bit\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    mult_shape1 = np.prod(model.layers[1].output_shape[1:])\n",
    "\n",
    "    # Second Convolutional layer\n",
    "    model.add(Conv2D(16, (k_size[1], k_size[1]), kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape1), padding='valid', activation='selu'))\n",
    "    # Reduce size a bit\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    mult_shape2 = np.prod(model.layers[3].output_shape[1:])\n",
    "\n",
    "    # Third Convolutional layer\n",
    "    model.add(Conv2D(16, (k_size[2], k_size[2]), kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape2), padding='valid', activation='selu'))\n",
    "    # Reduce size a bit\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    #Converting the 2D images to 1D vectors\n",
    "    model.add(Flatten())  \n",
    "    mult_shape3 = np.prod(model.layers[6].output_shape[1:])\n",
    "\n",
    "    # First Fully connected layer\n",
    "    model.add(Dense(200, activation='selu', kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    mult_shape4 = np.prod(model.layers[8].output_shape[1:])\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape4)))\n",
    "    \n",
    "    #### END OF MODEL ####\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    ## Save the Model and create Data path!\n",
    "    path_data = '../Data/{}/{}/'.format(str(datetime.now().strftime('%Y-%m-%d')), name )\n",
    "\n",
    "    if not os.path.exists(path_data):\n",
    "        os.makedirs(path_data)\n",
    "        print('Created path: {}'.format(path_data))\n",
    "\n",
    "    # Open the file\n",
    "    with open(path_data + 'ModelSummary.txt','w') as fh:\n",
    "        # Pass the file handle in as a lambda function to make it callable\n",
    "        model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "        \n",
    "    \n",
    "    #Defining optimiser and compiling the model\n",
    "    model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "                  optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = LossHistory()\n",
    "    \n",
    "    ## Start the training!\n",
    "    model.fit(X_train_norm, Y_train,  batch_size=76, epochs=100, verbose=1, validation_split = 0.05, callbacks=[history])\n",
    "\n",
    "    #Evaluating trained model on test images\n",
    "    score = model.evaluate(X_test_norm, Y_test, verbose=0)\n",
    "    print('Model has accuracy:', score[1]*100,'%')\n",
    "    \n",
    "    # Save trained NN\n",
    "    model.save(path_model + name + '.h5')\n",
    "    np.savetxt(path_model + name + '_TrainingData.txt', np.transpose([history.accuracy, history.losses]))\n",
    "    \n",
    "    ### Performance on Testdata! ###\n",
    "    # Get probs per image\n",
    "    probs = []\n",
    "\n",
    "    i=0 \n",
    "    for img in X_test_norm:\n",
    "        #plt.imshow(np.squeeze(img), cmap='gray')\n",
    "\n",
    "        img = np.reshape(img, [1,h,w,1])\n",
    "        p = model.predict_proba(img, verbose=0)\n",
    "        probs.append(np.squeeze(p))\n",
    "\n",
    "        #name = \"Good img\" if Y_test[i, 1] == 1 else \"Bad img\"\n",
    "        #plt.title('{}. Score: [{:.4f}, {:.4f}]'.format(name, p[0,0], p[0,1]))\n",
    "        #plt.savefig('../Plots/TestImg/{}.png'.format(i))\n",
    "        i+=1\n",
    "\n",
    "    probs = np.array(probs)\n",
    "    \n",
    "    np.savetxt(path_data + 'ScoresOnTestData.txt', np.transpose([Y_test, probs]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with 2 Conv and 2 Fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_2Conv_2Fully = ['167_163_200_200', '165_163_200_200']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_sizes_2Conv_2Fully = [(7,3), (5,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 167_163_200_200\tKernelsize: (7, 3)\n",
      "k_sizes: 7,3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 69, 94, 16)        800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 34, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 32, 45, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 16, 22, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 5632)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 200)               1126600   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,170,121\n",
      "Trainable params: 1,170,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Name: 165_163_200_200\tKernelsize: (5, 3)\n",
      "k_sizes: 5,3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 71, 96, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 35, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 33, 46, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 16, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 5888)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 200)               1177800   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 1,220,937\n",
      "Trainable params: 1,220,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for name, k_size in zip(names_2Conv_2Fully, kernel_sizes_2Conv_2Fully):\n",
    "    print('Name: {}\\tKernelsize: {}'.format(name, k_size))\n",
    "    #print('k_sizes: {},{}'.format(k_size[0], k_size[1]))\n",
    "    \n",
    "    ## Path for Model saving!\n",
    "    path_model = '../TrainedModels/' + str(datetime.now().strftime('%Y-%m-%d')) + '/'\n",
    "\n",
    "    if not os.path.exists(path_model):\n",
    "        os.makedirs(path_model)\n",
    "        print('Created path: {}'.format(path_model))\n",
    "    \n",
    "    #### MODEL ####\n",
    "    model = Sequential()\n",
    "\n",
    "    # First Convolutional layer initialised with random input weights\n",
    "    model.add(Conv2D(16, (k_size[0], k_size[0]), kernel_initializer=RandomNormal(mean=0, stddev=1/(h*w)), padding='valid', input_shape=input_shape, activation='selu'))\n",
    "    # Reduce size a bit\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    mult_shape1 = np.prod(model.layers[1].output_shape[1:])\n",
    "\n",
    "    # Second Convolutional layer\n",
    "    model.add(Conv2D(16, (k_size[1], k_size[1]), kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape1), padding='valid', activation='selu'))\n",
    "    # Reduce size a bit\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    #Converting the 2D images to 1D vectors\n",
    "    model.add(Flatten())  \n",
    "    mult_shape2 = np.prod(model.layers[4].output_shape[1:])\n",
    "\n",
    "    # First Fully connected layer\n",
    "    model.add(Dense(200, activation='selu', kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    mult_shape3 = np.prod(model.layers[6].output_shape[1:])\n",
    "\n",
    "    model.add(Dense(200, activation='selu', kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    mult_shape4 = np.prod(model.layers[8].output_shape[1:])\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=RandomNormal(mean=0, stddev=1/mult_shape4)))\n",
    "    \n",
    "    #### END OF MODEL ####\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    ## Save the Model and create Data path!\n",
    "    path_data = '../Data/{}/{}/'.format(str(datetime.now().strftime('%Y-%m-%d')), name )\n",
    "\n",
    "    if not os.path.exists(path_data):\n",
    "        os.makedirs(path_data)\n",
    "        print('Created path: {}'.format(path_data))\n",
    "\n",
    "    # Open the file\n",
    "    with open(path_data + 'ModelSummary.txt','w') as fh:\n",
    "        # Pass the file handle in as a lambda function to make it callable\n",
    "        model.summary(print_fn=lambda x: fh.write(x + '\\n'))\n",
    "        \n",
    "    \n",
    "    #Defining optimiser and compiling the model\n",
    "    model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "                  optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = LossHistory()\n",
    "    \n",
    "    ## Start the training!\n",
    "    model.fit(X_train_norm, Y_train,  batch_size=76, epochs=100, verbose=1, validation_split = 0.05, callbacks=[history])\n",
    "\n",
    "    #Evaluating trained model on test images\n",
    "    score = model.evaluate(X_test_norm, Y_test, verbose=0)\n",
    "    print('Model has accuracy:', score[1]*100,'%')\n",
    "    \n",
    "    # Save trained NN\n",
    "    model.save(path_model + name + '.h5')\n",
    "    np.savetxt(path_model + name + '_TrainingData.txt', np.transpose([history.accuracy, history.losses]))\n",
    "    \n",
    "    ### Performance on Testdata! ###\n",
    "    # Get probs per image\n",
    "    probs = []\n",
    "\n",
    "    i=0 \n",
    "    for img in X_test_norm:\n",
    "        #plt.imshow(np.squeeze(img), cmap='gray')\n",
    "\n",
    "        img = np.reshape(img, [1,h,w,1])\n",
    "        p = model.predict_proba(img, verbose=0)\n",
    "        probs.append(np.squeeze(p))\n",
    "\n",
    "        #name = \"Good img\" if Y_test[i, 1] == 1 else \"Bad img\"\n",
    "        #plt.title('{}. Score: [{:.4f}, {:.4f}]'.format(name, p[0,0], p[0,1]))\n",
    "        #plt.savefig('../Plots/TestImg/{}.png'.format(i))\n",
    "        i+=1\n",
    "\n",
    "    probs = np.array(probs)\n",
    "    \n",
    "    np.savetxt(path_data + 'ScoresOnTestData.txt', np.transpose([Y_test, probs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
